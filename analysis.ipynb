"""
MultiPriNTF NFT Market Analysis Framework
==================================

This notebook implements comprehensive analysis of NFT market data using the MultiPriNTF 
(Hybrid Variational Autoencoder-Transformer) architecture. The analysis framework 
is optimized for high-performance processing on multi-GPU systems.

Architecture Overview
-------------------
MultiPriNTF combines visual and transaction data analysis through:
1. Visual Processing: Convolutional networks for NFT image analysis
2. Transaction Processing: Transformer-based sequential analysis
3. Multi-modal Fusion: Cross-attention mechanism for feature integration

System Configuration
------------------
- Hardware: 3x NVIDIA RTX 3090 GPUs
- CUDA Version: 11.7
- System Memory: 128GB DDR4
"""

# Import required libraries
import torch
import torch.nn as nn
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
import json
from datetime import datetime
import h5py
from typing import Dict, List, Tuple, Optional
import logging
from tqdm import tqdm

# Import custom modules
from src.models.multimodal_architecture import MultimodalFusionEncoder
from src.models.security_module import SecureMultimodalFusion
from src.utils.data_loader import OptimizedNFTDataset

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class NFTMarketAnalyzer:
    """
    Comprehensive NFT market analysis system with advanced visualization 
    and metrics computation capabilities.
    """
    
    def __init__(
        self,
        data_dir: str,
        num_gpus: int = 3,
        batch_size: int = 128
    ):
        """
        Initialize the NFT market analyzer.
        
        Args:
            data_dir: Directory containing NFT data
            num_gpus: Number of available GPUs
            batch_size: Processing batch size
        """
        self.data_dir = Path(data_dir)
        self.num_gpus = num_gpus
        self.batch_size = batch_size
        
        # Initialize GPU settings
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        if torch.cuda.is_available():
            for i in range(num_gpus):
                gpu_props = torch.cuda.get_device_properties(i)
                logger.info(
                    f"GPU {i}: {gpu_props.name}, "
                    f"Memory: {gpu_props.total_memory / 1024**3:.1f} GB"
                )
        
        # Load and preprocess data
        self.dataset = self._load_dataset()
        self.transaction_stats = self._compute_transaction_statistics()
        
    def _load_dataset(self) -> OptimizedNFTDataset:
        """
        Load and prepare NFT dataset with optimized memory handling.
        """
        try:
            dataset = OptimizedNFTDataset(
                image_dir=self.data_dir / 'images',
                transaction_file=self.data_dir / 'transactions.jsonl',
                num_gpus=self.num_gpus
            )
            logger.info(f"Loaded dataset with {len(dataset)} entries")
            return dataset
        except Exception as e:
            logger.error(f"Error loading dataset: {e}")
            raise

    def _compute_transaction_statistics(self) -> Dict:
        """
        Compute comprehensive transaction statistics.
        """
        df = self.dataset.transactions
        
        stats = {
            'transaction_types': df['type'].value_counts().to_dict(),
            'price_stats': {
                'mean': df['eth'].mean(),
                'median': df['eth'].median(),
                'std': df['eth'].std(),
                'min': df['eth'].min(),
                'max': df['eth'].max()
            },
            'price_ranges': self._calculate_price_ranges(df),
            'type_analysis': self._analyze_punk_types(df),
            'attribute_stats': self._analyze_attributes(df)
        }
        
        return stats
        
    def _calculate_price_ranges(self, df: pd.DataFrame) -> Dict:
        """
        Calculate distribution of prices across different ranges.
        """
        ranges = [0, 1, 5, 10, 50, 100, float('inf')]
        labels = ['0-1', '1-5', '5-10', '10-50', '50-100', '100+']
        
        price_dist = pd.cut(
            df['eth'], 
            bins=ranges, 
            labels=labels
        ).value_counts()
        
        return {
            'distribution': price_dist.to_dict(),
            'percentages': (price_dist / len(df) * 100).to_dict()
        }
        
    def _analyze_punk_types(self, df: pd.DataFrame) -> Dict:
        """
        Analyze statistics for different punk types.
        """
        type_stats = df.groupby('type').agg({
            'eth': ['mean', 'min', 'max', 'count']
        }).round(2)
        
        return type_stats.to_dict()
        
    def _analyze_attributes(self, df: pd.DataFrame) -> Dict:
        """
        Analyze value and distribution of NFT attributes.
        """
        attribute_stats = {}
        for attr in df['accessories'].explode().unique():
            if pd.isna(attr):
                continue
                
            attr_data = df[df['accessories'].apply(lambda x: attr in x)]
            attribute_stats[attr] = {
                'count': len(attr_data),
                'avg_price': attr_data['eth'].mean(),
                'max_price': attr_data['eth'].max(),
                'type_distribution': attr_data['type'].value_counts().to_dict()
            }
            
        return attribute_stats

    def analyze_market_trends(self) -> Dict:
        """
        Analyze market trends and patterns.
        """
        df = self.dataset.transactions
        
        # Calculate daily volume
        daily_volume = df.groupby(
            pd.to_datetime(df['timestamp']).dt.date
        )['eth'].sum()
        
        # Calculate market efficiency metrics
        price_changes = df['eth'].pct_change()
        
        market_metrics = {
            'daily_volume': daily_volume.to_dict(),
            'volatility': price_changes.std(),
            'market_depth': len(df) / (
                df['timestamp'].max() - df['timestamp'].min()
            ).days,
            'liquidity_score': self._calculate_liquidity_score(df)
        }
        
        return market_metrics
        
    def _calculate_liquidity_score(self, df: pd.DataFrame) -> float:
        """
        Calculate market liquidity score.
        """
        # Calculate average time between transactions
        times = pd.to_datetime(df['timestamp'])
        time_diffs = times.diff().dt.total_seconds()
        
        # Calculate volume-weighted average time
        weighted_time = np.average(
            time_diffs, 
            weights=df['eth'],
            where=~np.isnan(time_diffs)
        )
        
        # Higher score indicates better liquidity
        return 1 / (1 + weighted_time/3600)  # Normalize to hours

    def visualize_market_analysis(self):
        """
        Generate comprehensive market analysis visualizations.
        """
        # Create visualization directory
        vis_dir = self.data_dir / 'visualizations'
        vis_dir.mkdir(exist_ok=True)
        
        # Generate various plots
        self._plot_price_distribution(vis_dir)
        self._plot_transaction_types(vis_dir)
        self._plot_time_series(vis_dir)
        self._plot_attribute_analysis(vis_dir)
        
    def _plot_price_distribution(self, vis_dir: Path):
        """
        Plot price distribution analysis.
        """
        plt.figure(figsize=(12, 6))
        
        # Price histogram
        sns.histplot(
            data=self.dataset.transactions,
            x='eth',
            bins=50,
            log_scale=True
        )
        
        plt.title('NFT Price Distribution')
        plt.xlabel('Price (ETH)')
        plt.ylabel('Count')
        plt.savefig(vis_dir / 'price_distribution.png', dpi=300)
        plt.close()
        
    def _plot_transaction_types(self, vis_dir: Path):
        """
        Plot transaction type analysis.
        """
        plt.figure(figsize=(12, 6))
        
        data = pd.DataFrame(
            self.transaction_stats['transaction_types'].items(),
            columns=['Type', 'Count']
        )
        
        sns.barplot(data=data, x='Type', y='Count')
        plt.xticks(rotation=45)
        plt.title('Transaction Type Distribution')
        plt.tight_layout()
        plt.savefig(vis_dir / 'transaction_types.png', dpi=300)
        plt.close()
        
    def _plot_time_series(self, vis_dir: Path):
        """
        Plot time series analysis.
        """
        plt.figure(figsize=(15, 8))
        
        # Daily volume
        daily_volume = pd.Series(
            self.analyze_market_trends()['daily_volume']
        )
        
        daily_volume.plot()
        plt.title('Daily Trading Volume')
        plt.xlabel('Date')
        plt.ylabel('Volume (ETH)')
        plt.savefig(vis_dir / 'daily_volume.png', dpi=300)
        plt.close()
        
    def _plot_attribute_analysis(self, vis_dir: Path):
        """
        Plot attribute value analysis.
        """
        plt.figure(figsize=(15, 8))
        
        # Top 10 valuable attributes
        attr_data = pd.DataFrame(self.transaction_stats['attribute_stats']).T
        top_10 = attr_data.nlargest(10, 'avg_price')
        
        sns.barplot(
            data=top_10,
            x=top_10.index,
            y='avg_price'
        )
        
        plt.xticks(rotation=45)
        plt.title('Top 10 Most Valuable Attributes')
        plt.xlabel('Attribute')
        plt.ylabel('Average Price (ETH)')
        plt.tight_layout()
        plt.savefig(vis_dir / 'valuable_attributes.png', dpi=300)
        plt.close()

    def generate_analysis_report(self) -> str:
        """
        Generate comprehensive analysis report.
        """
        report = f"""
        NFT Market Analysis Report
        ========================
        Generated on: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

        Dataset Overview
        ---------------
        Total Transactions: {len(self.dataset.transactions)}
        Total Volume: {self.dataset.transactions['eth'].sum():,.2f} ETH
        Unique NFTs: {len(self.dataset.transactions['id'].unique()):,}
        
        Market Statistics
        ----------------
        Average Price: {self.transaction_stats['price_stats']['mean']:,.2f} ETH
        Median Price: {self.transaction_stats['price_stats']['median']:,.2f} ETH
        Price Volatility: {self.transaction_stats['price_stats']['std']:,.2f} ETH
        
        Market Efficiency Metrics
        -----------------------
        Market Depth: {self.analyze_market_trends()['market_depth']:.2f} transactions/day
        Liquidity Score: {self.analyze_market_trends()['liquidity_score']:.2f}
        Volatility: {self.analyze_market_trends()['volatility']:.2%}
        """
        
        # Save report
        with open(self.data_dir / 'analysis_report.md', 'w') as f:
            f.write(report)
            
        return report

# Example usage
if __name__ == "__main__":
    analyzer = NFTMarketAnalyzer(
        data_dir="data/nft_dataset",
        num_gpus=3,
        batch_size=128
    )
    
    # Run analysis
    analyzer.visualize_market_analysis()
    report = analyzer.generate_analysis_report()
    print("Analysis completed successfully!")